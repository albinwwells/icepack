{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os, os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import firedrake\n",
    "import icepack, icepack.plot, icepack.models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse problems\n",
    "\n",
    "In this demo, we'll revisit the Larsen Ice Shelf.\n",
    "This time, we're going to estimate the fluidity coefficient $A$ in Glen's flow law\n",
    "\n",
    "$$\\dot\\varepsilon = A\\tau^3$$\n",
    "\n",
    "from observational data.\n",
    "In the previous demos, we've come up with some value of the fluidity coefficient and computed a velocity field by solving an elliptic partial differential equation.\n",
    "The fluidity coefficient is roughly a known function of the ice temperature, together with some fudge factors for crystal fabric or large-scale damage, so we know an approximate range of values that it could take.\n",
    "Nonetheless, we don't have large-scale measurements of the fluidity coefficient from remote sensing like we do for ice velocity and thickness.\n",
    "\n",
    "Instead, we can try to come up with a value of $A$ that gives a velocity field closest to what we observed.\n",
    "This idea can be turned into a constrained optimization problem.\n",
    "The quantity we wish to optimize is the misfit between the computed velocity $u$ and the observed velocity $u^o$:\n",
    "\n",
    "$$E(u) = \\frac{1}{2}\\int_\\Omega\\left(\\frac{u - u^o}{\\sigma}\\right)^2dx,$$\n",
    "\n",
    "where $\\sigma$ are the standard deviations of the measurements.\n",
    "\n",
    "One constraint is that the fluidity field has to be positive.\n",
    "Inequality constraints can require substantially more sophisticated numerical methods.\n",
    "To avoid this problem, we'll cheat our way out by reparameterizing $A$ in terms of a new variable $\\theta$:\n",
    "\n",
    "$$A = A_0e^{-\\theta/n},$$\n",
    "\n",
    "where $n$ is the Glen flow law exponent.\n",
    "No matter the value of $\\theta$, $A$ is always positive.\n",
    "To make this change, we'll give the `IceShelf` object our own custom-made function for calculating the viscous part of the action functional, just like we did for the friction in the last demo.\n",
    "\n",
    "In addition to minimizing the misfit, we also want to have a relatively smooth value of the parameter field $\\theta$.\n",
    "The regularization functional $R$ is included to penalize oscillations over a given length scale $L$:\n",
    "\n",
    "$$R(\\theta) = \\frac{L^2}{2}\\int_\\Omega|\\nabla \\theta|^2dx.$$\n",
    "\n",
    "Finally, let $F(u, \\theta)$ be the weak form of the shallow shelf equations, again using the new parameter $\\theta$ instead of the fluidity $A$.\n",
    "The physics constraint for our problem is that $F(u, \\theta) = 0$.\n",
    "We can enforce this constraint by introducing the Lagrange multiplier $\\lambda$, in which case the combined objective functional is\n",
    "\n",
    "$$J(u, \\theta; \\lambda) = E(u) + R(\\theta) + \\langle F(u, \\theta), \\lambda\\rangle.$$\n",
    "\n",
    "We can calculate the derivative of this functional with respect to $\\theta$ by using the *adjoint method*.\n",
    "We can then use a descent method to iterate towards a critical point, which is hopefully close to the true value of the fluidity coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data\n",
    "\n",
    "The input data are just as in the previous demo for the Larsen Ice Shelf, but we also need to use the error estimates for the velocities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = os.environ['ICEPACK_DATA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = firedrake.Mesh(os.path.join(data_directory, \"meshes/larsen/larsen.msh\"))\n",
    "\n",
    "fig, axes = icepack.plot.subplots()\n",
    "axes.set_xlabel('meters')\n",
    "axes.grid()\n",
    "icepack.plot.triplot(mesh, axes=axes, linewidth=2)\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icepack.grid import arcinfo, GridData\n",
    "thickness = arcinfo.read(os.path.join(data_directory, \"bedmap2/larsen-h.txt\"))\n",
    "vx = arcinfo.read(os.path.join(data_directory, \"measures_antarctica/larsen-vx.txt\"))\n",
    "vy = arcinfo.read(os.path.join(data_directory, \"measures_antarctica/larsen-vy.txt\"))\n",
    "err = arcinfo.read(os.path.join(data_directory, \"measures_antarctica/larsen-err.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import preprocess\n",
    "vx = preprocess(vx, mesh)\n",
    "vy = preprocess(vy, mesh)\n",
    "thickness = preprocess(thickness, mesh, radius=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 2\n",
    "Q = firedrake.FunctionSpace(mesh, 'CG', degree)\n",
    "V = firedrake.VectorFunctionSpace(mesh, 'CG', degree)\n",
    "\n",
    "h = icepack.interpolate(thickness, Q)\n",
    "u_obs = icepack.interpolate(lambda x: (vx(x), vy(x)), V)\n",
    "σ = icepack.interpolate(err, Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll plot the velocity errors.\n",
    "You can see from the stripey pattern that they depend on the particular swath from the observational platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = icepack.plot.subplots()\n",
    "contours = icepack.plot.tricontourf(σ, 20, axes=ax)\n",
    "fig.colorbar(contours)\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make an initial guess for the fluidity parameter.\n",
    "In this case, we'll use the same value as in the second demo -- a constant fluidity assuming a temperature of $-13^\\circ$C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T0 = 260\n",
    "A0 = icepack.rate_factor(T0)\n",
    "from icepack.constants import glen_flow_law as n\n",
    "def viscosity(u, h, θ):\n",
    "    A = A0 * firedrake.exp(-θ / n)\n",
    "    return icepack.models.viscosity.viscosity_depth_averaged(u, h, A)\n",
    "\n",
    "θ = firedrake.Function(Q)\n",
    "\n",
    "ice_shelf = icepack.models.IceShelf(viscosity=viscosity)\n",
    "opts = {'dirichlet_ids': [3, 4, 5, 6, 7, 8], 'tol': 1e-6}\n",
    "u = ice_shelf.diagnostic_solve(u0=u_obs, h=h, θ=θ, **opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = icepack.plot.subplots()\n",
    "contours = icepack.plot.tricontourf(u, 20, axes=ax)\n",
    "fig.colorbar(contours)\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferring the fluidity\n",
    "\n",
    "Solving an inverse problem has lots of moving parts, all of which are wrapped in a class that inherits from `icepack.inverse.InverseSolver`.\n",
    "In our case, we'll be using the gradient descent method, which is implemented in `GradientDescentSolver`.\n",
    "Using this class should save you from worrying about too many low-level details, but still provide a good amount of flexibility and transparency.\n",
    "There are five parts that go into an inverse problem:\n",
    "\n",
    "* a physics model\n",
    "* an initial guess for the parameter and state\n",
    "* an error metric\n",
    "* a smoothness metric\n",
    "\n",
    "We already have the first two, so it remains to decide how we'll measure the misfit and smoothness.\n",
    "Here we'll use the $L^2$-norm error for the velocities and the mean-square gradient for the fluidity, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from firedrake import inner, grad, dx\n",
    "import icepack.inverse\n",
    "\n",
    "objective = 0.5 * (inner(u - u_obs, u - u_obs)) / σ**2 * dx\n",
    "\n",
    "L = 5e3\n",
    "regularization = 0.5 * L**2 * inner(grad(θ), grad(θ)) * dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a convenience, the inverse problem object allows you to call a function of your choice at the end of every iteration.\n",
    "For this demonstration, we'll have it print out the values of the misfit and regularization functionals.\n",
    "You could also, say, make a plot of the state and parameter guess at every iteration to make a movie of how the algorithm progresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = firedrake.assemble(firedrake.Constant(1) * dx(mesh))\n",
    "def print_error_and_regularization(inverse_problem):\n",
    "    E = firedrake.assemble(inverse_problem.objective)\n",
    "    R = firedrake.assemble(inverse_problem.regularization)\n",
    "    print('{:g}, {:g}'.format(E/area, R/area))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create the `InverseProblem` object.\n",
    "We've already mentioned several objects that the inverse problem needs -- the model, the initial guess, some functionals, etc.\n",
    "Additionally, it needs to know the name of the observed field and the parameter (the `state_name` and `parameter_name`) arguments, since these values are passed to the forward solver as keyword arguments.\n",
    "All the additional arguments to the forward model are passed as a dictionary `model_args`.\n",
    "In our case, these consist of the thickness field, the initial guess for the velocity, and the forward solver tolerance.\n",
    "Finally, to specify the inverse problem, we need to know where Dirichlet boundary conditions are to be applied, as this affects how one solves for the Lagrange multiplier field $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = icepack.inverse.InverseProblem(\n",
    "    model=ice_shelf,\n",
    "    method=icepack.models.IceShelf.diagnostic_solve,\n",
    "    objective=objective,\n",
    "    regularization=regularization,\n",
    "    state_name='u',\n",
    "    state=u,\n",
    "    parameter_name='θ',\n",
    "    parameter=θ,\n",
    "    model_args={'h': h, 'u0': u, 'tol': 1e-6},\n",
    "    dirichlet_ids=[3, 4, 5, 6, 7, 8]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've created the problem, we then create a solver object that will iteratively search for a good value of the parameters.\n",
    "The solver object is distinct from the problem so that it's easier to customize how the solver works.\n",
    "In this case, we'll use the gradient descent method.\n",
    "Gradient descent is quite slow, but it's the easiest to implement and can serve as a reference by which to judge other method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = icepack.inverse.GradientDescentSolver(problem, print_error_and_regularization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before setting the solver loose, let's look at the initial search direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = icepack.plot.subplots()\n",
    "contours = icepack.plot.tricontourf(solver.search_direction, 20, axes=ax)\n",
    "fig.colorbar(contours)\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The search direction is obtained by multiplying the inverse of the finite element mass matrix $M$ by the gradient $dJ$ of the objective function, which has the virtue of simplicity.\n",
    "Keeping in mind that these values will be exponentiated to obtain the fluidity field $A$ in Glen's flow law, we can see that this search direction is very badly scaled.\n",
    "Consequently, the algorithm has to do lots of backtracking to find a good interval in which to search.\n",
    "\n",
    "The solve method takes in a relative convergence tolerance, an absolute tolerance, and a maximum number of iterations, and it returns the total number of iterations necessary to achieve the given tolerances.\n",
    "In our case, we'll stop once the relative decrease in the objective function from one iteration to the next is less than 1/200.\n",
    "\n",
    "The algorithm takes a while to run.\n",
    "Now would be the time to put on a fresh pot of coffee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = solver.solve(\n",
    "    rtol=5e-3,\n",
    "    atol=0.0,\n",
    "    max_iterations=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "Now that we're done, we'll want to to some post-processing and analysis on the fluidity parameter that we inferred.\n",
    "The inverse problem object stores the parameter we're inferring and the observed field as the properties `parameter` and `state` respectively.\n",
    "The names are intentionally not specific to just ice shelves.\n",
    "For other problems, we might instead be inferring a friction coefficient rather than a fluidity, or we might be observing the thickness instead of the velocity.\n",
    "You can see all the publicly visible properties by typing `help(inverse_problem)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = icepack.plot.subplots()\n",
    "ctr = icepack.plot.tricontourf(solver.parameter, 40, axes=ax)\n",
    "fig.colorbar(ctr)\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fluidity is much higher around areas of heavy crevassing, and much lower around the northern edge of the ice shelf.\n",
    "It's possible that some of the ice is actually grounded here, and the velocities are actually a result of basal drag.\n",
    "In that case, the algorithm will erroneously give a low value of the fluidity, since that's the only variable at hand for explaining the observed velocities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = icepack.plot.subplots()\n",
    "ctr = icepack.plot.tricontourf(solver.state, 40, axes=ax)\n",
    "fig.colorbar(ctr)\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computed ice velocity is mostly similar to observations, but doesn't quite capture the sharp change in velocity near the big rift by Gipps Ice Rise.\n",
    "We regularized the problem by looking only for smooth values of the fluidity parameter.\n",
    "As a consequence, we won't be able to see sharp changes that might result from features like crevasses or rifts.\n",
    "We might instead try to use the total variation functional\n",
    "\n",
    "$$R(\\theta) = L\\int_\\Omega|\\nabla\\theta|dx$$\n",
    "\n",
    "if we were interested in features like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = icepack.plot.subplots()\n",
    "ctr = icepack.plot.tricontourf(solver.adjoint_state, 40, axes=ax)\n",
    "fig.colorbar(ctr)\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the adjoint state field directly can give us some idea of what areas of the ice shelf make the biggest difference for the total error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's try and see how different the inferred parameter is from our naive guess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(icepack.norm(solver.parameter) / np.sqrt(area))\n",
    "print(firedrake.assemble(solver.objective) / area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective function has been reduced by more than 3 throughout this iteration, and our final approximation departs quite substantially from the initial guess.\n",
    "This suggests data assimilation gives a substantial benefit compared to picking a sensible constant value.\n",
    "\n",
    "The value of the misfit functional divided by the ice shelf area should be around 1/2, provided that we had a good value of the fluidity parameter.\n",
    "While the approximation we've found is an improvement over a naive guess, it leaves much to be desired still."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this demo, we've shown how to back out the fluidity of an ice shelf from remote sensing observations.\n",
    "We could then use this value, together with a description of how the fluidity evolves, to initialize a prognostic model of the ice shelf.\n",
    "For example, we might assume that the fluidity is a function of ice temperature and damage.\n",
    "The evolution equations for these fields are fairly simple hyperbolic PDE for which we can write solvers using firedrake.\n",
    "\n",
    "The value of the fluidity that we obtained is not at all spatially homogeneous.\n",
    "Unless we were very clever, we probably couldn't have come up with some way to parameterize it to get a reasonable guess.\n",
    "\n",
    "We would expect from statistical estimation theory that the misfit functional divided by the shelf area will be around 1/2, since a sum of squared normal random variables has a $\\chi^2$-distribution.\n",
    "We are quite far off from that.\n",
    "There are a number of reasons why this might happen.\n",
    "\n",
    "* The error estimates $\\sigma$ are wrong.\n",
    "* We don't have a good way to also account for thickness errors, which are substantial.\n",
    "* We regularized the problem too much.\n",
    "* The ice shelf becomes grounded on some pinning point and we didn't add basal drag.\n",
    "* The numerical optimization algorithm we used converges slowly.\n",
    "* I implemented the numerical optimization algorithm incorrectly.\n",
    "\n",
    "It's probably a superposition of all of the above.\n",
    "In any case, there's quite a bit of improvement possible on what we've shown here."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
